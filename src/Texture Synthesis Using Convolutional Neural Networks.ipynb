{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _\"Texture Synthesis Using Convolutional Neural Networks\" - Tensorflow 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "实现分为4步\n",
    "- 预处理图像\n",
    "- 自定义网络结构，设置权重\n",
    "- 计算损失函数\n",
    "- 训练并生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path_to_img):\n",
    "  max_dim = 512\n",
    "  img = tf.io.read_file(path_to_img)\n",
    "  img = tf.image.decode_image(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "  long_dim = max(shape)\n",
    "  scale = max_dim / long_dim\n",
    "\n",
    "  new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "  img = tf.image.resize(img, new_shape)\n",
    "  img = img[tf.newaxis, :]\n",
    "  return img    ###使用tensorflow的官方接口读取图像，设定最大尺寸为512，以便于训练，测试结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置初始权重，本实现只使用了style_weight，其他可以后续测试时额外添加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_weight=1\n",
    "total_variation_weight=1e-3\n",
    "norm_term = 6\n",
    "norm_weight = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一步 图像预处理\n",
    "读取图片，并生成初始噪声图像\n",
    "vgg所需要的图像格式在模型内部处理，不在此处实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_path = \"texture_5.png\"#读取纹理图片\n",
    "style_image = load_img(style_path)#转换为张量\n",
    "image = tf.Variable(tf.random.normal(shape=style_image.shape,mean=0,stddev=1))  #用纹理图像生成初始噪声图像\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二步 自定义网络模型\n",
    "- 将vgg19中的最大池化改为平均池化，可以使结果更加平滑\n",
    "- 根据所需要的层提取出只有指定层输出的新模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAvePolConfig(configDict):\n",
    "  configDict['class_name']= 'AveragePooling2D'\n",
    "  configDict['padding'] = 'same'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatModel():\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    config = vgg.get_config()\n",
    "    layersConfig = config['layers']\n",
    "    pool_index=  [3,6,11,16,21]\n",
    "    for i in pool_index:\n",
    "      setAvePolConfig(layersConfig[i])\n",
    "    model = tf.keras.Model.from_config(config)\n",
    "    model.set_weights(vgg.get_weights())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_layers(layer_names,vgg):\n",
    "  outputs = [vgg.get_layer(name).output for name in layer_names]\n",
    "  model = tf.keras.Model([vgg.input], outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg = creatModel() #自定义vgg模型\n",
    "style_layers = [layer.name for layer in custom_vgg.layers][1:] #除了input层，其他全加入风格损失\n",
    "num_style_layers = len(style_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_extractor = vgg_layers(style_layers,custom_vgg)\n",
    "style_outputs = style_extractor(style_image*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三步 获取噪声图像的输出，计算损失函数\n",
    "单层损失函数设置为 L = (每层的格拉姆矩阵之差的平方和)*weight\n",
    "\n",
    "总损失函数为各层的L之和\n",
    "\n",
    "对损失函数进行梯度下降，不断更新像素值，就能得到目标的纹理结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input_tensor):#计算格拉姆矩阵\n",
    "  result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "  input_shape = tf.shape(input_tensor)\n",
    "  num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
    "  return result/(num_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss(outputs):\n",
    "    style_outputs = outputs['style']\n",
    "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) \n",
    "                           for name in style_outputs.keys()])\n",
    "    style_loss *= style_weight / num_style_layers\n",
    "\n",
    "    loss = style_loss\n",
    "    return loss #纹理风格损失，其中style_loss是每层的目标图像和原始图像格拉姆矩阵之差的平方和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''获取所需要的各层输出'''\n",
    "class StyleModel(tf.keras.models.Model):\n",
    "  def __init__(self, style_layers,model):\n",
    "    super(StyleModel, self).__init__()\n",
    "    self.vgg =  vgg_layers(style_layers,model)\n",
    "    self.style_layers = style_layers\n",
    "    self.num_style_layers = len(style_layers)\n",
    "    self.vgg.trainable = False\n",
    "\n",
    "  def call(self, inputs):\n",
    "    \"Expects float input in [0,1]\"\n",
    "    inputs = inputs*255.0\n",
    "    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
    "    outputs = self.vgg(preprocessed_input)\n",
    "    style_outputs = (outputs[:self.num_style_layers])\n",
    "\n",
    "    style_outputs = [gram_matrix(style_output)\n",
    "                     for style_output in style_outputs]\n",
    "\n",
    "    style_dict = {style_name:value\n",
    "                  for style_name, value\n",
    "                  in zip(self.style_layers, style_outputs)}\n",
    "    \n",
    "    return {'style':style_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = StyleModel(style_layers,custom_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_targets = extractor(style_image)['style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 第四步，开启训练\n",
    "论文中推荐使用LBFGS算法，但因为调用困难，此次选择Adam优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.optimizers.Adam(learning_rate=0.2, beta_1=0.99, epsilon=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_0_1(image):\n",
    "  return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0) #像素切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(image):\n",
    "  with tf.GradientTape() as tape:\n",
    "    outputs = extractor(image)\n",
    "    loss = style_loss(outputs)\n",
    "    #loss = style_loss(outputs)+noise_loss(image) 图像自身的范式和\n",
    "    #loss += total_variation_weight*total_variation_loss(image) #总变分损失\n",
    "  grad = tape.gradient(loss, image)\n",
    "  opt.apply_gradients([(grad, image)])\n",
    "  image.assign(clip_0_1(image)) #由于模型要求输入要在[0,1]，进行范围限制\n",
    "  train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 进行训练，一般来说6000-7000次可以得到简单纹理令人满意的结果\n",
    "import time\n",
    "\n",
    "epochs = 70\n",
    "steps_per_epoch = 100\n",
    "\n",
    "step = 0\n",
    "for n in range(epochs):\n",
    "  for m in range(steps_per_epoch):\n",
    "    step += 1\n",
    "    train_step(image)\n",
    "    print(\".\", end='')\n",
    "  plt.imshow(image.read_value()[0])\n",
    "  plt.title(\"Train step: {}\".format(step))\n",
    "  print(train_loss.result())\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''张量转化为图片'''\n",
    "import PIL\n",
    "def tensor_to_image(tensor):\n",
    "  tensor = tensor*255\n",
    "  tensor = np.array(tensor, dtype=np.uint8)\n",
    "  if np.ndim(tensor)>3:\n",
    "    assert tensor.shape[0] == 1\n",
    "    tensor = tensor[0]\n",
    "  return PIL.Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = tensor_to_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file.save(\"out.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###直方图匹配，暂时未用到\n",
    "def hist_match(img,ref):\n",
    "  out = np.zeros_like(img)\n",
    "  _, _, colorChannel = img.shape\n",
    "  for i in range(colorChannel):\n",
    "      print(i)\n",
    "      hist_img, _ = np.histogram(img[:, :, i], 256)   # get the histogram\n",
    "      hist_ref, _ = np.histogram(ref[:, :, i], 256)\n",
    "      cdf_img = np.cumsum(hist_img)   # get the accumulative histogram\n",
    "      cdf_ref = np.cumsum(hist_ref)\n",
    "  \n",
    "      for j in range(256):\n",
    "          tmp = abs(cdf_img[j] - cdf_ref)\n",
    "          tmp = tmp.tolist()\n",
    "          idx = tmp.index(min(tmp))   # find the smallest number in tmp, get the index of this number\n",
    "          out[:, :, i][img[:, :, i] == j] = idx\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_pass_x_y(image):\n",
    "  x_var = image[:,:,1:,:] - image[:,:,:-1,:]\n",
    "  y_var = image[:,1:,:,:] - image[:,:-1,:,:]\n",
    "\n",
    "  return x_var, y_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss(image):#总变分损失\n",
    "  x_deltas, y_deltas = high_pass_x_y(image)\n",
    "  return tf.reduce_mean(x_deltas**2) + tf.reduce_mean(y_deltas**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_loss(diffs):\n",
    "    shape = diffs.get_shape().as_list()\n",
    "    size = reduce(lambda x, y: x * y, shape) ** 2\n",
    "    sum_of_squared_diffs = tf.reduce_sum(tf.square(diffs))\n",
    "    return sum_of_squared_diffs / size #目标图像噪声损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_loss(X):\n",
    "    return (norm_loss(X)**norm_term)*norm_weight"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitdeeplearningcondab784c4fd53f74b2b97465d54101de53b",
   "display_name": "Python 3.7.7 64-bit ('deeplearning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}